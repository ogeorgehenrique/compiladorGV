#Etapa 2: Analisador L√©xico

O arquivo scanner.py implementa a primeira fase da compila√ß√£o, chamada an√°lise l√©xica, respons√°vel por quebrar o c√≥digo-fonte em unidades l√©xicas (tokens). Esta etapa √© crucial para preparar o c√≥digo para a an√°lise sint√°tica.

‚∏ª

# Objetivo da an√°lise l√©xica

Transformar o c√≥digo-fonte bruto (texto) em uma sequ√™ncia de tokens, que s√£o unidades significativas da linguagem, como:
- Identificadores (x, main, contador)
- Palavras-chave (int, retorna, se)
- Operadores (+, =, ==)
	‚Ä¢	s√≠mbolos (;, {, })
	‚Ä¢	literais ("texto", 42, 3.14)

Componentes envolvidos na an√°lise l√©xica

| Arquivo/Classe               | Fun√ß√£o                                                                 |
|-----------------------------|------------------------------------------------------------------------|
| `CompiladorGVLexer.g4`      | Arquivo de gram√°tica l√©xica usado pelo ANTLR para gerar o `CompiladorGVLexer`. |
| `CompiladorGVLexer.py`      | Gerado automaticamente pelo ANTLR a partir da gram√°tica `.g4`.        |
| `scanner.py`                | Script principal que executa a an√°lise l√©xica.                         |
| `CommonTokenStream` (ANTLR4)| Estrutura de dados que armazena os tokens extra√≠dos.                  |
| `MyLexerErrorListener.py` (opcional) | (Se usado) Define um ouvinte personalizado para lidar com erros l√©xicos de forma amig√°vel. |

Funcionamento detalhado

1. üì• Leitura do arquivo-fonte

O scanner.py recebe o caminho de um arquivo de c√≥digo-fonte como argumento, e o l√™ usando o FileStream, transformando-o em um stream de caracteres UTF-8.

```
input_stream = FileStream(argv[1], encoding='utf-8')
```

2. üßæ Tokeniza√ß√£o via Lexer (CompiladorGVLexer)

Esse texto √© passado para o CompiladorGVLexer, classe gerada automaticamente pelo ANTLR a partir da gram√°tica .g4. Ela aplica as regras l√©xicas e identifica os tokens v√°lidos.

```
lexer = CompiladorGVLexer(input_stream)
```

3. üßπ Coleta dos tokens via CommonTokenStream

O resultado √© encapsulado em um CommonTokenStream, que √© uma lista ordenada de tokens que pode ser passada para o parser posteriormente.

```
tokens = CommonTokenStream(lexer)
```

4. üì§ Impress√£o formatada dos tokens

O scanner.py pode iterar sobre os tokens e imprimi-los no terminal com informa√ß√µes √∫teis:

```
<Tipo, 'Lexema', Linha, Coluna>
```
exemplo:
```
<ID, 'contador', Linha 1, Coluna 4>
<ATRIBUICAO, '=', Linha 1, Coluna 13>
<INTEIRO, '10', Linha 1, Coluna 15>
```

5. üö® Tratamento de erros l√©xicos (se implementado)

Se o c√≥digo conter s√≠mbolos inv√°lidos (ex: @, #, &), o lexer pode disparar um erro. Caso voc√™ implemente um MyLexerErrorListener, ele pode interceptar esses erros e mostrar mensagens personalizadas, como:

```
ERRO L√âXICO [Linha 1, Coluna 5]: S√≠mbolo '@' n√£o reconhecido pela linguagem.
```

# Import√¢ncia dessa etapa

A an√°lise l√©xica √© a base de todo o processo de compila√ß√£o. Ela garante que os s√≠mbolos do c√≥digo est√£o corretos, respeitam a sintaxe da linguagem e s√£o compreens√≠veis para as etapas seguintes (sint√°tica, sem√¢ntica, etc). Um erro aqui impede qualquer an√°lise posterior.